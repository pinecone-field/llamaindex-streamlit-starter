{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize PDF File with LlamaIndex and Pinecone\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install -U llama-index \\\n",
    "    llama-index-readers-file \\\n",
    "    llama-index-vector-stores-pinecone \\\n",
    "    pinecone-client \\\n",
    "    arxiv==2.1.0 \\\n",
    "    python-dotenv \\\n",
    "    setuptools  # (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Set environment variables for API keys\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set file and index names\n",
    "index_name = os.getenv(\"INDEX_NAME\")\n",
    "file_path = os.getenv(\"FILE_PATH\")\n",
    "doc_title = os.getenv(\"DOCUMENT_TITLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process PDF with LlamaIndex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PDFReader\n",
    "\n",
    "loader = PDFReader()\n",
    "\n",
    "documents = loader.load_data(file=Path(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect imported file\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up document content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "\n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", content)\n",
    "\n",
    "    # Remove specific unwanted patterns and characters\n",
    "    unwanted_patterns = [\n",
    "        \"\\\\n\",\n",
    "        \"  —\",\n",
    "        \"——————————\",\n",
    "        \"—————————\",\n",
    "        \"—————\",\n",
    "        r\"\\\\u[\\dA-Fa-f]{4}\",\n",
    "        r\"\\uf075\",\n",
    "        r\"\\uf0b7\",\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \" \", content)\n",
    "\n",
    "    # Fix improperly spaced hyphenated words and normalize whitespace\n",
    "    content = re.sub(r\"(\\w)\\s*-\\s*(\\w)\", r\"\\1-\\2\", content)\n",
    "    content = re.sub(r\"\\s+\", \" \", content)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "# Call function\n",
    "cleaned_docs = []\n",
    "for d in documents:\n",
    "    cleaned_text = clean_up_text(d.text)\n",
    "    d.text = cleaned_text\n",
    "    cleaned_docs.append(d)\n",
    "\n",
    "# Inspect output\n",
    "cleaned_docs[0].get_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through `documents` and add our new key:value pairs\n",
    "metadata_additions = {\"title\": doc_title}\n",
    "\n",
    "# Update dict in place\n",
    "[cd.metadata.update(metadata_additions) for cd in cleaned_docs]\n",
    "\n",
    "# Let\\'s confirm everything worked:\n",
    "cleaned_docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# This will be the model we use both for Node parsing and for vectorization\n",
    "embed_model = OpenAIEmbedding(api_key=openai_api_key)\n",
    "\n",
    "# Define the initial pipeline\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SemanticSplitterNodeParser(\n",
    "            buffer_size=1,\n",
    "            breakpoint_percentile_threshold=95,\n",
    "            embed_model=embed_model,\n",
    "        ),\n",
    "        embed_model,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upsert vectors to Pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "\n",
    "# Initialize connection to Pinecone\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "# check if index already exists\n",
    "if index_name not in existing_indexes:\n",
    "    # Create your index (can skip this step if your index already exists)\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-west-2\"),\n",
    "    )\n",
    "\n",
    "# Initialize your index\n",
    "pinecone_index = pc.Index(index_name)\n",
    "\n",
    "# Initialize VectorStore\n",
    "# OPTIONAL: upsert to namespace by commenting out the first line and uncommenting the second\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "# vector_store = PineconeVectorStore(pinecone_index=pinecone_index, namespace=\"<NAMESPACE_NAME>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our pipeline with the addition of our PineconeVectorStore\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SemanticSplitterNodeParser(\n",
    "            buffer_size=1,\n",
    "            breakpoint_percentile_threshold=95,\n",
    "            embed_model=embed_model,\n",
    "        ),\n",
    "        embed_model,\n",
    "    ],\n",
    "    vector_store=vector_store,  # Our new addition\n",
    ")\n",
    "\n",
    "# Now we run our pipeline!\n",
    "pipeline.run(documents=cleaned_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a test query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query relevant to your document content\n",
    "test_query = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from IPython.display import display\n",
    "\n",
    "# Instantiate VectorStoreIndex object from your vector_store object\n",
    "vector_index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n",
    "\n",
    "query_engine = vector_index.as_query_engine()\n",
    "response = query_engine.query(test_query)\n",
    "\n",
    "# Inspect results\n",
    "display(response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
